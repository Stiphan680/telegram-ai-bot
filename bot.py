"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ULTIMATE ADVANCED TELEGRAM AI BOT v2.0            â•‘
â•‘                                                           â•‘
â•‘  ğŸ¤– Features:                                            â•‘
â•‘     âœ… Deep Thinking AI Chat (Claude-Level Intelligence)  â•‘
â•‘     âœ… Image Generation (Multiple Styles)                 â•‘
â•‘     âœ… Video Generation                                   â•‘
â•‘     âœ… Advanced Code Generation                           â•‘
â•‘     âœ… Multi-Language Translation                         â•‘
â•‘     âœ… Smart Conversation Memory (10 messages)            â•‘
â•‘     âœ… Intent Recognition (NLP)                           â•‘
â•‘     âœ… Rate Limiting & Security                           â•‘
â•‘     âœ… Health Monitoring                                  â•‘
â•‘     âœ… Context-Aware Responses                            â•‘
â•‘     âœ… Advanced Error Handling                            â•‘
â•‘                                                           â•‘
â•‘  Author: AI Developer                                    â•‘
â•‘  Version: 2.0 - Full Stack Advanced Features             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import telebot
import requests
import json
import os
from datetime import datetime
import logging
from dotenv import load_dotenv
from functools import wraps
from time import time
import threading
from flask import Flask, jsonify
from collections import deque
import time as time_module

# Load environment variables
load_dotenv()

# ============ CONFIGURATION ============
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN', '8401689004:AAEvNNZQJCoVh6UMwUGrKOUynDPd-1rsPAk')
AI_API_URL = os.getenv('AI_API_URL', 'https://ai-api-premium-server.onrender.com')
ADMIN_ID = int(os.getenv('ADMIN_ID', '0'))
LOG_LEVEL = os.getenv('LOG_LEVEL', 'INFO')
PORT = int(os.getenv('PORT', 10000))
MAX_MEMORY_SIZE = 10
DEEP_THINKING_MODEL = "claude-3.5-sonnet-thinking"
STANDARD_MODEL = "claude-3"

# Initialize bot
bot = telebot.TeleBot(TELEGRAM_TOKEN)
app = Flask(__name__)

# Configure logging
logging.basicConfig(
    level=getattr(logging, LOG_LEVEL),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============ FLASK HEALTH ENDPOINTS ============
@app.route('/', methods=['GET'])
def home():
    return jsonify({
        'status': 'running',
        'service': 'ULTIMATE Advanced Telegram AI Bot',
        'version': '2.0',
        'features': [
            'deep_thinking_ai',
            'image_generation',
            'video_generation',
            'advanced_code',
            'translation',
            'memory_system',
            'npl_intent',
            'context_aware'
        ],
        'timestamp': datetime.now().isoformat()
    })

@app.route('/health', methods=['GET'])
def health():
    api_health = ai_client.check_health() if 'ai_client' in globals() else False
    return jsonify({
        'bot': 'online',
        'api': 'healthy' if api_health else 'offline',
        'memory_active': True,
        'thinking_ai': 'enabled',
        'timestamp': datetime.now().isoformat()
    })

@app.route('/status', methods=['GET'])
def status():
    return jsonify({
        'bot_running': True,
        'ai_model': DEEP_THINKING_MODEL,
        'ai_api_url': AI_API_URL,
        'features_enabled': [
            'deep_thinking',
            'image',
            'video',
            'code',
            'translate',
            'memory',
            'context'
        ],
        'timestamp': datetime.now().isoformat()
    })

# ============ ADVANCED CONVERSATION MEMORY ============
class ConversationMemory:
    """Advanced memory system with context awareness"""
    
    def __init__(self, max_size=10):
        self.memory = {}
        self.max_size = max_size
        self.user_topics = {}  # Track user interests
        self.user_preferences = {}  # Remember preferences
    
    def add_message(self, user_id, role, message):
        if user_id not in self.memory:
            self.memory[user_id] = deque(maxlen=self.max_size)
        
        self.memory[user_id].append({
            "role": role,
            "message": message,
            "timestamp": datetime.now().isoformat()
        })
        logger.info(f"ğŸ’¾ Memory: User {user_id} - {role}: {message[:60]}...")
    
    def get_history(self, user_id, last_n=5):
        if user_id not in self.memory:
            return []
        history = list(self.memory[user_id])
        return history[-last_n:] if len(history) > last_n else history
    
    def get_context_string(self, user_id, last_n=5):
        """Get enriched context with memory"""
        history = self.get_history(user_id, last_n)
        if not history:
            return ""
        
        context = "\nğŸ“š **PREVIOUS CONVERSATION CONTEXT:**\n"
        for entry in history:
            role = "ğŸ‘¤ User" if entry["role"] == "user" else "ğŸ¤– Assistant"
            context += f"{role}: {entry['message']}\n"
        context += "**END OF CONTEXT**\n\n"
        return context
    
    def clear_history(self, user_id):
        if user_id in self.memory:
            self.memory[user_id].clear()
        if user_id in self.user_topics:
            del self.user_topics[user_id]
        return True
    
    def get_stats(self):
        total_users = len(self.memory)
        total_messages = sum(len(h) for h in self.memory.values())
        return {
            "total_users": total_users,
            "total_messages": total_messages,
            "max_size": self.max_size
        }

conversation_memory = ConversationMemory(max_size=MAX_MEMORY_SIZE)

# ============ ADVANCED RATE LIMITER ============
class AdvancedRateLimiter:
    """Smart rate limiting with different tiers"""
    
    def __init__(self):
        self.user_calls = {}
        self.limits = {
            'standard': {'calls': 20, 'period': 60},
            'thinking': {'calls': 5, 'period': 120},
            'generation': {'calls': 3, 'period': 300}
        }
    
    def is_allowed(self, user_id, tier='standard'):
        now = time()
        if user_id not in self.user_calls:
            self.user_calls[user_id] = {}
        
        if tier not in self.user_calls[user_id]:
            self.user_calls[user_id][tier] = []
        
        limit = self.limits[tier]
        self.user_calls[user_id][tier] = [
            t for t in self.user_calls[user_id][tier]
            if now - t < limit['period']
        ]
        
        if len(self.user_calls[user_id][tier]) < limit['calls']:
            self.user_calls[user_id][tier].append(now)
            return True
        return False

rate_limiter = AdvancedRateLimiter()

# ============ ADVANCED NLP INTENT RECOGNITION ============
class AdvancedIntentRecognizer:
    """Enhanced NLP for accurate intent detection"""
    
    def __init__(self):
        self.intents = {
            "deep_thinking": {
                "keywords": [
                    "à¤¸à¥‹à¤šà¥‹", "à¤µà¤¿à¤¶à¥à¤²à¥‡à¤·à¤£", "à¤—à¤¹à¤°à¤¾à¤ˆ à¤¸à¥‡", "à¤¸à¤®à¤à¤¾à¤“ à¤µà¤¿à¤¸à¥à¤¤à¤¾à¤° à¤¸à¥‡",
                    "think", "analyze", "deep", "explain in detail",
                    "à¤¸à¤®à¤", "reason", "logic", "à¤•à¥à¤¯à¥‹à¤‚", "à¤•à¥ˆà¤¸à¥‡", "why", "how"
                ],
                "type": "deep_thinking"
            },
            "image": {
                "keywords": [
                    "image", "photo", "picture", "draw", "banao",
                    "à¤¤à¤¸à¥à¤µà¥€à¤°", "à¤«à¥‹à¤Ÿà¥‹", "à¤šà¤¿à¤¤à¥à¤°", "generate image", "à¤¬à¤¨à¤¾à¤“ image"
                ],
                "type": "image"
            },
            "video": {
                "keywords": [
                    "video", "film", "clip", "generate video",
                    "à¤µà¥€à¤¡à¤¿à¤¯à¥‹", "à¤¬à¤¨à¤¾à¤“ video", "video banao"
                ],
                "type": "video"
            },
            "code": {
                "keywords": [
                    "code", "program", "python", "javascript", "à¤²à¤¿à¤–",
                    "à¤•à¥‹à¤¡", "à¤ªà¥à¤°à¥‹à¤—à¥à¤°à¤¾à¤®", "à¤²à¤¿à¤–à¥‹ code", "write code"
                ],
                "type": "code"
            },
            "translate": {
                "keywords": [
                    "translate", "à¤…à¤¨à¥à¤µà¤¾à¤¦", "à¤¹à¤¿à¤‚à¤¦à¥€", "english", "convert"
                ],
                "type": "translate"
            },
            "chat": {
                "keywords": [
                    "hello", "hi", "à¤¨à¤®à¤¸à¥à¤¤à¥‡", "à¤¬à¤¾à¤¤", "chat", "talk"
                ],
                "type": "chat"
            }
        }
    
    def recognize_intent(self, text):
        text_lower = text.lower()
        
        # Check for deep thinking keywords first (highest priority)
        for intent, data in self.intents.items():
            if data["type"] == "deep_thinking":
                for keyword in data["keywords"]:
                    if keyword.lower() in text_lower:
                        return {
                            "intent": intent,
                            "type": "deep_thinking",
                            "confidence": 0.95
                        }
        
        # Check other intents
        for intent, data in self.intents.items():
            if data["type"] != "deep_thinking":
                for keyword in data["keywords"]:
                    if keyword.lower() in text_lower:
                        return {
                            "intent": intent,
                            "type": data["type"],
                            "confidence": 0.85
                        }
        
        # Default to chat
        return {
            "intent": "general_query",
            "type": "chat",
            "confidence": 0.5
        }

intent_recognizer = AdvancedIntentRecognizer()

# ============ ADVANCED AI API CLIENT ============
class AdvancedAIAPIClient:
    """Enhanced API client with multiple AI models"""
    
    def __init__(self, base_url):
        self.base_url = base_url
        self.timeout = 120  # Increased for thinking
    
    def check_health(self):
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def deep_thinking_chat(self, message, context=""):
        """ğŸ§  Deep Thinking AI - Like Claude with Extended Thinking"""
        try:
            full_message = context + message if context else message
            
            payload = {
                "message": full_message,
                "model": DEEP_THINKING_MODEL,
                "max_tokens": 2000,
                "thinking": True,
                "temperature": 0.7,
                "deep_analysis": True
            }
            
            logger.info(f"ğŸ§  Deep Thinking Request: {message[:50]}...")
            response = requests.post(
                f"{self.base_url}/api/chat",
                json=payload,
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                return response.json()
            return {"error": f"API Error: {response.status_code}"}
        except Exception as e:
            logger.error(f"Deep thinking error: {e}")
            return {"error": str(e)}
    
    def standard_chat(self, message, context=""):
        """Standard AI Chat"""
        try:
            full_message = context + message if context else message
            
            payload = {
                "message": full_message,
                "model": STANDARD_MODEL,
                "max_tokens": 1000
            }
            
            response = requests.post(
                f"{self.base_url}/api/chat",
                json=payload,
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                return response.json()
            return {"error": f"API Error: {response.status_code}"}
        except Exception as e:
            return {"error": str(e)}
    
    def generate_image(self, prompt, style="realistic"):
        """ğŸ¨ Advanced Image Generation"""
        try:
            logger.info(f"ğŸ¨ Image Generation: {prompt}")
            
            payload = {
                "prompt": prompt,
                "style": style,
                "size": "1024x1024",
                "quality": "high",
                "detailed": True
            }
            
            response = requests.post(
                f"{self.base_url}/api/image",
                json=payload,
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                return response.json()
            return {"error": f"Image generation failed: {response.status_code}"}
        except Exception as e:
            logger.error(f"Image gen error: {e}")
            return {"error": str(e)}
    
    def generate_video(self, description, duration=10):
        """ğŸ¥ Advanced Video Generation"""
        try:
            logger.info(f"ğŸ¥ Video Generation: {description}")
            
            payload = {
                "description": description,
                "duration": duration,
                "quality": "1080p",
                "detailed": True
            }
            
            response = requests.post(
                f"{self.base_url}/api/video",
                json=payload,
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                return response.json()
            return {"error": f"Video generation failed: {response.status_code}"}
        except Exception as e:
            logger.error(f"Video gen error: {e}")
            return {"error": str(e)}
    
    def generate_code(self, description, language="python"):
        """ğŸ’» Advanced Code Generation"""
        try:
            payload = {
                "description": description,
                "language": language,
                "detailed": True,
                "with_comments": True
            }
            
            response = requests.post(
                f"{self.base_url}/api/code",
                json=payload,
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                return response.json()
            return {"error": f"Code generation failed"}
        except Exception as e:
            return {"error": str(e)}
    
    def translate(self, text, target_language="hindi"):
        """ğŸŒ Advanced Translation"""
        try:
            payload = {
                "text": text,
                "target_language": target_language,
                "preserve_meaning": True
            }
            
            response = requests.post(
                f"{self.base_url}/api/translate",
                json=payload,
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                return response.json()
            return {"error": "Translation failed"}
        except Exception as e:
            return {"error": str(e)}

ai_client = AdvancedAIAPIClient(AI_API_URL)

# ============ KEYBOARD BUILDERS ============
def get_main_menu():
    markup = telebot.types.ReplyKeyboardMarkup(row_width=2, resize_keyboard=True)
    buttons = [
        telebot.types.KeyboardButton("ğŸ§  Deep Thinking AI"),
        telebot.types.KeyboardButton("ğŸ’¬ Smart Chat"),
        telebot.types.KeyboardButton("ğŸ¨ Generate Image"),
        telebot.types.KeyboardButton("ğŸ¥ Generate Video"),
        telebot.types.KeyboardButton("ğŸ’» Generate Code"),
        telebot.types.KeyboardButton("ğŸŒ Translate"),
        telebot.types.KeyboardButton("ğŸ§  My Memory"),
        telebot.types.KeyboardButton("â“ Help")
    ]
    markup.add(*buttons)
    return markup

def get_thinking_styles():
    markup = telebot.types.ReplyKeyboardMarkup(row_width=2, resize_keyboard=True)
    buttons = [
        telebot.types.KeyboardButton("ğŸ”¬ Analytical"),
        telebot.types.KeyboardButton("ğŸ“ Educational"),
        telebot.types.KeyboardButton("ğŸ’¡ Creative"),
        telebot.types.KeyboardButton("âš™ï¸ Technical"),
        telebot.types.KeyboardButton("ğŸ“š Philosophical"),
        telebot.types.KeyboardButton("â¬…ï¸ Back")
    ]
    markup.add(*buttons)
    return markup

def get_image_styles():
    markup = telebot.types.ReplyKeyboardMarkup(row_width=2, resize_keyboard=True)
    buttons = [
        telebot.types.KeyboardButton("ğŸ–¼ï¸ Realistic"),
        telebot.types.KeyboardButton("ğŸ¨ Artistic"),
        telebot.types.KeyboardButton("ğŸŒˆ Fantasy"),
        telebot.types.KeyboardButton("ğŸ­ Cinematic"),
        telebot.types.KeyboardButton("ğŸ–Œï¸ Oil Painting"),
        telebot.types.KeyboardButton("â¬…ï¸ Back")
    ]
    markup.add(*buttons)
    return markup

def get_memory_menu():
    markup = telebot.types.ReplyKeyboardMarkup(row_width=2, resize_keyboard=True)
    buttons = [
        telebot.types.KeyboardButton("ğŸ“œ View History"),
        telebot.types.KeyboardButton("ğŸ“Š Memory Stats"),
        telebot.types.KeyboardButton("ğŸ—‘ï¸ Clear Memory"),
        telebot.types.KeyboardButton("â¬…ï¸ Back to Menu")
    ]
    markup.add(*buttons)
    return markup

# ============ ERROR HANDLER ============
def error_handler(func):
    @wraps(func)
    def wrapper(message, *args, **kwargs):
        try:
            return func(message, *args, **kwargs)
        except Exception as e:
            logger.error(f"âŒ Error in {func.__name__}: {str(e)}")
            bot.send_message(
                message.chat.id,
                f"âŒ à¤•à¥à¤› à¤—à¤²à¤¤ à¤¹à¥à¤†à¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¦à¥‹à¤¬à¤¾à¤°à¤¾ à¤•à¥‹à¤¶à¤¿à¤¶ à¤•à¤°à¥‡à¤‚à¥¤\n\nError: {str(e)[:50]}...",
                reply_markup=get_main_menu()
            )
    return wrapper

# ============ BOT COMMANDS ============
@bot.message_handler(commands=['start'])
@error_handler
def handle_start(message):
    user_name = message.from_user.first_name
    user_id = message.chat.id
    conversation_memory.clear_history(user_id)
    
    welcome = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ğŸš€ ULTIMATE ADVANCED AI BOT v2.0 ğŸš€   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

à¤¨à¤®à¤¸à¥à¤¤à¥‡ {user_name}! ğŸ‘‹

âœ¨ **à¤®à¥ˆà¤‚ à¤¹à¥‚à¤ à¤¸à¤¬à¤¸à¥‡ Advanced AI Bot:**

ğŸ§  **Deep Thinking AI** - Claude-Level Intelligence
   â€¢ à¤—à¤¹à¤°à¤¾à¤ˆ à¤¸à¥‡ à¤¸à¥‹à¤šà¤¤à¤¾ à¤¹à¥‚à¤
   â€¢ à¤œà¤Ÿà¤¿à¤² à¤¸à¤®à¤¸à¥à¤¯à¤¾à¤“à¤‚ à¤•à¤¾ à¤¸à¤®à¤¾à¤§à¤¾à¤¨
   â€¢ à¤µà¤¿à¤¸à¥à¤¤à¥ƒà¤¤ à¤µà¤¿à¤¶à¥à¤²à¥‡à¤·à¤£

ğŸ’¬ **Smart Chat** - Context à¤•à¥‡ à¤¸à¤¾à¤¥ à¤¬à¤¾à¤¤à¤šà¥€à¤¤
ğŸ’» **Code Generation** - à¤•à¤¿à¤¸à¥€ à¤­à¥€ language à¤®à¥‡à¤‚
ğŸ¨ **Image Generation** - 6 à¤…à¤²à¤—-à¤…à¤²à¤— styles
ğŸ¥ **Video Generation** - Professional quality
ğŸŒ **Translation** - 50+ languages
ğŸ§  **Smart Memory** - 10 messages à¤¯à¤¾à¤¦ à¤°à¤–à¤¤à¤¾ à¤¹à¥‚à¤

**à¤•à¥à¤¯à¤¾ à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¤¤à¥‡ à¤¹à¥‹?**
"""
    
    bot.send_message(message.chat.id, welcome, reply_markup=get_main_menu(), parse_mode='Markdown')

@bot.message_handler(commands=['help'])
@error_handler
def handle_help(message):
    help_text = f"""
ğŸ“š **ADVANCED FEATURES GUIDE**

1ï¸âƒ£ **ğŸ§  Deep Thinking AI**
   â€¢ à¤¸à¤¬à¤¸à¥‡ intelligent thinking
   â€¢ "à¤—à¤¹à¤°à¤¾à¤ˆ à¤¸à¥‡ à¤¸à¥‹à¤šà¥‹" à¤œà¥ˆà¤¸à¥‡ keywords à¤¦à¥‹
   â€¢ 5 à¤…à¤²à¤— thinking styles

2ï¸âƒ£ **ğŸ’¬ Smart Chat**
   â€¢ Context-aware responses
   â€¢ Memory à¤•à¥‡ à¤¸à¤¾à¤¥ à¤¬à¥‡à¤¹à¤¤à¤° à¤œà¤µà¤¾à¤¬
   â€¢ Multi-language support

3ï¸âƒ£ **ğŸ¨ Image Generation**
   â€¢ 6 professional styles
   â€¢ High quality 1024x1024
   â€¢ Detailed descriptions

4ï¸âƒ£ **ğŸ¥ Video Generation**
   â€¢ Professional quality videos
   â€¢ 10+ seconds duration
   â€¢ Multiple effects

5ï¸âƒ£ **ğŸ’» Code Generation**
   â€¢ 20+ programming languages
   â€¢ Detailed comments
   â€¢ Production-ready code

6ï¸âƒ£ **ğŸŒ Translation**
   â€¢ 50+ languages
   â€¢ Natural translations
   â€¢ Context preservation

7ï¸âƒ£ **ğŸ§  Smart Memory**
   â€¢ Last 10 conversations à¤¯à¤¾à¤¦ à¤°à¤–à¤¤à¤¾ à¤¹à¥‚à¤
   â€¢ Better context awareness
   â€¢ Personal preferences

**à¤‰à¤¦à¤¾à¤¹à¤°à¤£:**
â€¢ "à¤—à¤¹à¤°à¤¾à¤ˆ à¤¸à¥‡ à¤¸à¥‹à¤šà¥‹ à¤•à¤¿ à¤•à¥ˆà¤¸à¥‡ AI à¤•à¤¾à¤® à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ"
â€¢ "Sunset à¤•à¥€ image à¤¬à¤¨à¤¾à¤“ oil painting style à¤®à¥‡à¤‚"
â€¢ "Python à¤®à¥‡à¤‚ machine learning code à¤²à¤¿à¤–à¥‹"

ğŸš€ **Let's Get Started!**
"""
    
    bot.send_message(message.chat.id, help_text, reply_markup=get_main_menu(), parse_mode='Markdown')

@bot.message_handler(commands=['status'])
@error_handler
def handle_status(message):
    api_health = ai_client.check_health()
    memory_stats = conversation_memory.get_stats()
    
    status_text = f"""
ğŸ“Š **BOT STATUS & STATS**

**System Status:**
âœ… Bot: ONLINE
{'âœ…' if api_health else 'âŒ'} API: {'HEALTHY' if api_health else 'OFFLINE'}
âœ… Memory: ACTIVE
âœ… Deep Thinking: ENABLED
âœ… Generation: READY

**Memory Statistics:**
ğŸ“ˆ Total Users: {memory_stats['total_users']}
ğŸ“ Total Messages: {memory_stats['total_messages']}
ğŸ’¾ Max/User: {memory_stats['max_size']}

**Models:**
ğŸ§  Deep Thinking: {DEEP_THINKING_MODEL}
ğŸ’¬ Standard: {STANDARD_MODEL}

â° Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S IST')}
"""
    
    bot.send_message(message.chat.id, status_text, parse_mode='Markdown')

# ============ DEEP THINKING AI HANDLER ============
@bot.message_handler(func=lambda m: "Deep Thinking AI" in m.text)
@error_handler
def handle_deep_thinking_mode(message):
    if not rate_limiter.is_allowed(message.chat.id, 'thinking'):
        bot.send_message(
            message.chat.id,
            "âš ï¸ Deep Thinking Rate Limit: 5 requests per 2 minutes\n\nà¤•à¥à¤› à¤¸à¤®à¤¯ à¤¬à¤¾à¤¦ à¤•à¥‹à¤¶à¤¿à¤¶ à¤•à¤°à¥‡à¤‚à¥¤"
        )
        return
    
    thinking_intro = """
ğŸ§  **DEEP THINKING MODE ACTIVATED**

**5 Thinking Styles:**
â€¢ ğŸ”¬ **Analytical** - Data-driven analysis
â€¢ ğŸ“ **Educational** - Learning-focused
â€¢ ğŸ’¡ **Creative** - Out-of-box thinking
â€¢ âš™ï¸ **Technical** - Deep technical insights
â€¢ ğŸ“š **Philosophical** - Deep reasoning

à¤…à¤ªà¤¨à¤¾ thinking style à¤šà¥à¤¨à¥‹, à¤«à¤¿à¤° à¤¸à¤µà¤¾à¤² à¤ªà¥‚à¤›à¥‹!
"""
    
    msg = bot.send_message(
        message.chat.id,
        thinking_intro,
        reply_markup=get_thinking_styles(),
        parse_mode='Markdown'
    )
    bot.register_next_step_handler(msg, process_thinking_style)

def process_thinking_style(message):
    user_id = message.chat.id
    
    if "Back" in message.text:
        bot.send_message(user_id, "Main Menu:", reply_markup=get_main_menu())
        return
    
    style = message.text.replace("ğŸ”¬ ", "").replace("ğŸ“ ", "").replace("ğŸ’¡ ", "").replace("âš™ï¸ ", "").replace("ğŸ“š ", "")
    
    msg = bot.send_message(
        user_id,
        f"\nğŸ§  {style} Mode à¤šà¥à¤¨à¤¾ à¤¹à¥ˆà¥¤\n\nà¤…à¤¬ à¤…à¤ªà¤¨à¤¾ à¤—à¤¹à¤°à¤¾ à¤¸à¤µà¤¾à¤² à¤ªà¥‚à¤›à¥‹:\n\n(à¤œà¤¿à¤¤à¤¨à¤¾ à¤µà¤¿à¤¸à¥à¤¤à¤¾à¤° à¤¸à¥‡ à¤ªà¥‚à¤›à¥‹à¤—à¥‡, à¤‰à¤¤à¤¨à¤¾ à¤µà¤¿à¤¸à¥à¤¤à¤¾à¤° à¤¸à¥‡ à¤œà¤µà¤¾à¤¬ à¤®à¤¿à¤²à¥‡à¤—à¤¾)",
        parse_mode='Markdown'
    )
    bot.register_next_step_handler(msg, process_deep_thinking, style)

def process_deep_thinking(message, style):
    user_id = message.chat.id
    user_question = message.text
    
    if not rate_limiter.is_allowed(user_id, 'thinking'):
        bot.send_message(user_id, "âš ï¸ Rate limit. à¤¥à¥‹à¤¡à¤¼à¤¾ à¤‡à¤‚à¤¤à¤œà¤¼à¤¾à¤° à¤•à¤°à¥‹à¥¤")
        return
    
    conversation_memory.add_message(user_id, "user", f"[{style}] {user_question}")
    
    thinking_msg = bot.send_message(
        user_id,
        "ğŸ§  à¤—à¤¹à¤°à¤¾à¤ˆ à¤¸à¥‡ à¤¸à¥‹à¤š à¤°à¤¹à¤¾ à¤¹à¥‚à¤... (à¤¯à¤¹ 30-60 à¤¸à¥‡à¤•à¤‚à¤¡ à¤²à¥‡ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ)\n\nâ³ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤ªà¥à¤°à¤¤à¥€à¤•à¥à¤·à¤¾ à¤•à¤°à¥‡à¤‚..."
    )
    
    context = conversation_memory.get_context_string(user_id, last_n=3)
    thinking_prompt = f"""
{style} Mode - Deep Thinking Request:

{user_question}

Please provide:
1. Deep analysis with reasoning
2. Multiple perspectives
3. Detailed explanations
4. Examples if applicable
5. Actionable insights
"""
    
    response = ai_client.deep_thinking_chat(thinking_prompt, context)
    
    if "error" not in response:
        ai_reply = response.get("response", "à¤•à¥‹à¤ˆ reply à¤¨à¤¹à¥€à¤‚ à¤®à¤¿à¤²à¤¾")
        
        # Format deep thinking response
        formatted_reply = f"""ğŸ§  **{style} Analysis:**\n\n{ai_reply}"""
        
        conversation_memory.add_message(user_id, "bot", ai_reply)
        
        if len(formatted_reply) > 4096:
            for i in range(0, len(formatted_reply), 4096):
                bot.send_message(user_id, formatted_reply[i:i+4096], parse_mode='Markdown')
            bot.delete_message(user_id, thinking_msg.message_id)
        else:
            bot.edit_message_text(formatted_reply, user_id, thinking_msg.message_id, parse_mode='Markdown')
    else:
        bot.edit_message_text(
            f"âŒ Error: {response['error']}",
            user_id,
            thinking_msg.message_id
        )
    
    bot.send_message(user_id, "\n à¤”à¤° à¤•à¥‹à¤ˆ à¤¸à¤µà¤¾à¤²?", reply_markup=get_main_menu())

# ============ IMAGE GENERATION HANDLER ============
@bot.message_handler(func=lambda m: "Generate Image" in m.text)
@error_handler
def handle_image_mode(message):
    if not rate_limiter.is_allowed(message.chat.id, 'generation'):
        bot.send_message(
            message.chat.id,
            "âš ï¸ Image Generation Rate Limit: 3 per 5 minutes\n\nà¤¥à¥‹à¤¡à¤¼à¤¾ à¤‡à¤‚à¤¤à¤œà¤¼à¤¾à¤° à¤•à¤°à¥‹à¥¤"
        )
        return
    
    image_intro = """
ğŸ¨ **IMAGE GENERATION MODE**

**6 Professional Styles:**
â€¢ ğŸ–¼ï¸ **Realistic** - Photo-realistic images
â€¢ ğŸ¨ **Artistic** - Artistic rendering
â€¢ ğŸŒˆ **Fantasy** - Fantasy worlds
â€¢ ğŸ­ **Cinematic** - Movie-quality
â€¢ ğŸ–Œï¸ **Oil Painting** - Classical style
â€¢ ğŸŒŒ **Sci-Fi** - Futuristic

Style à¤šà¥à¤¨à¥‹, à¤«à¤¿à¤° description à¤¦à¥‹!
"""
    
    msg = bot.send_message(
        message.chat.id,
        image_intro,
        reply_markup=get_image_styles(),
        parse_mode='Markdown'
    )
    bot.register_next_step_handler(msg, process_image_style)

def process_image_style(message):
    user_id = message.chat.id
    
    if "Back" in message.text:
        bot.send_message(user_id, "Main Menu:", reply_markup=get_main_menu())
        return
    
    style_map = {
        "ğŸ–¼ï¸ Realistic": "realistic",
        "ğŸ¨ Artistic": "artistic",
        "ğŸŒˆ Fantasy": "fantasy",
        "ğŸ­ Cinematic": "cinematic",
        "ğŸ–Œï¸ Oil Painting": "oil_painting",
        "ğŸŒŒ Sci-Fi": "scifi"
    }
    
    style = style_map.get(message.text, "realistic")
    
    msg = bot.send_message(
        user_id,
        f"\nğŸ¨ {message.text} à¤šà¥à¤¨à¤¾à¥¤\n\nà¤…à¤¬ detailed description à¤¦à¥‹:\n(à¤œà¤¿à¤¤à¤¨à¤¾ à¤µà¤¿à¤¸à¥à¤¤à¤¾à¤° à¤¸à¥‡ à¤¬à¤¤à¤¾à¤“à¤—à¥‡, à¤‰à¤¤à¤¨à¥€ à¤¬à¥‡à¤¹à¤¤à¤° image à¤¬à¤¨à¥‡à¤—à¥€)",
        parse_mode='Markdown'
    )
    bot.register_next_step_handler(msg, process_image_request, style)

def process_image_request(message, style):
    user_id = message.chat.id
    prompt = message.text
    
    if not rate_limiter.is_allowed(user_id, 'generation'):
        bot.send_message(user_id, "âš ï¸ Rate limit. à¤•à¥à¤› à¤¸à¤®à¤¯ à¤¬à¤¾à¤¦ à¤•à¥‹à¤¶à¤¿à¤¶ à¤•à¤°à¥‹à¥¤")
        return
    
    conversation_memory.add_message(user_id, "user", f"Image: {prompt}")
    
    processing = bot.send_message(
        user_id,
        f"ğŸ¨ {style.replace('_', ' ').title()} style à¤®à¥‡à¤‚ image à¤¬à¤¨ à¤°à¤¹à¥€ à¤¹à¥ˆ...\n\nâ³ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤ªà¥à¤°à¤¤à¥€à¤•à¥à¤·à¤¾ à¤•à¤°à¥‡à¤‚ (1-2 à¤®à¤¿à¤¨à¤Ÿ à¤²à¥‡ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ)..."
    )
    
    response = ai_client.generate_image(prompt, style)
    
    if "error" not in response and "image_url" in response:
        try:
            bot.send_photo(
                user_id,
                response["image_url"],
                caption=f"âœ¨ **{style.title()}** Style\n\nğŸ“ Prompt: {prompt[:100]}...",
                parse_mode='Markdown'
            )
            bot.delete_message(user_id, processing.message_id)
            conversation_memory.add_message(user_id, "bot", f"Generated: {prompt}")
        except Exception as e:
            bot.edit_message_text(
                f"âŒ Error sending image: {str(e)[:100]}",
                user_id,
                processing.message_id
            )
    else:
        bot.edit_message_text(
            f"âŒ Image Generation Failed:\n{response.get('error', 'Unknown error')}",
            user_id,
            processing.message_id
        )
    
    bot.send_message(user_id, "\n à¤”à¤° à¤•à¥à¤›?", reply_markup=get_main_menu())

# ============ VIDEO GENERATION HANDLER ============
@bot.message_handler(func=lambda m: "Generate Video" in m.text)
@error_handler
def handle_video_mode(message):
    if not rate_limiter.is_allowed(message.chat.id, 'generation'):
        bot.send_message(
            message.chat.id,
            "âš ï¸ Video Generation Rate Limit: 3 per 5 minutes\n\nà¤¥à¥‹à¤¡à¤¼à¤¾ à¤‡à¤‚à¤¤à¤œà¤¼à¤¾à¤° à¤•à¤°à¥‹à¥¤"
        )
        return
    
    msg = bot.send_message(
        message.chat.id,
        "ğŸ¥ **VIDEO GENERATION MODE**\n\nDetailed video description à¤¦à¥‹:\n(Example: 'Sunset à¤•à¥‡ à¤¸à¤®à¤¯ ocean à¤•à¥€ waves')",
        parse_mode='Markdown'
    )
    bot.register_next_step_handler(msg, process_video_request)

def process_video_request(message):
    user_id = message.chat.id
    description = message.text
    
    if not rate_limiter.is_allowed(user_id, 'generation'):
        bot.send_message(user_id, "âš ï¸ Rate limit")
        return
    
    conversation_memory.add_message(user_id, "user", f"Video: {description}")
    
    processing = bot.send_message(
        user_id,
        "ğŸ¥ Professional quality video à¤¬à¤¨ à¤°à¤¹à¥€ à¤¹à¥ˆ...\n\nâ³ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤ªà¥à¤°à¤¤à¥€à¤•à¥à¤·à¤¾ à¤•à¤°à¥‡à¤‚ (2-5 à¤®à¤¿à¤¨à¤Ÿ)..."
    )
    
    response = ai_client.generate_video(description, duration=10)
    
    if "error" not in response and "video_url" in response:
        try:
            bot.send_video(
                user_id,
                response["video_url"],
                caption=f"ğŸ¬ Professional Video\n\nğŸ“: {description[:80]}...",
                parse_mode='Markdown'
            )
            bot.delete_message(user_id, processing.message_id)
            conversation_memory.add_message(user_id, "bot", f"Generated video")
        except Exception as e:
            bot.edit_message_text(
                f"âŒ Error: {str(e)[:100]}",
                user_id,
                processing.message_id
            )
    else:
        bot.edit_message_text(
            f"âŒ Video Generation Failed\n{response.get('error', 'Unknown')}",
            user_id,
            processing.message_id
        )
    
    bot.send_message(user_id, "\n à¤”à¤°?", reply_markup=get_main_menu())

# ============ CODE GENERATION HANDLER ============
@bot.message_handler(func=lambda m: "Generate Code" in m.text)
@error_handler
def handle_code_mode(message):
    if not rate_limiter.is_allowed(message.chat.id, 'standard'):
        bot.send_message(message.chat.id, "âš ï¸ Rate limit. à¤•à¥à¤› à¤¸à¤®à¤¯ à¤¬à¤¾à¤¦ à¤•à¥‹à¤¶à¤¿à¤¶ à¤•à¤°à¥‹à¥¤")
        return
    
    msg = bot.send_message(
        message.chat.id,
        "ğŸ’» **ADVANCED CODE GENERATION**\n\nà¤•à¥à¤¯à¤¾ code à¤šà¤¾à¤¹à¤¿à¤?\n(Example: 'Python à¤®à¥‡à¤‚ machine learning model')",
        parse_mode='Markdown'
    )
    bot.register_next_step_handler(msg, process_code_request)

def process_code_request(message):
    user_id = message.chat.id
    
    conversation_memory.add_message(user_id, "user", f"Code: {message.text}")
    
    bot.send_message(user_id, "ğŸ’» Professional code à¤²à¤¿à¤– à¤°à¤¹à¤¾ à¤¹à¥‚à¤...")
    response = ai_client.generate_code(message.text, "python")
    
    if "error" not in response and "code" in response:
        code = response["code"]
        conversation_memory.add_message(user_id, "bot", f"Code generated")
        
        if len(code) > 4096:
            for i in range(0, len(code), 4096):
                bot.send_message(user_id, f"```python\n{code[i:i+4096]}\n```", parse_mode='Markdown')
        else:
            bot.send_message(user_id, f"```python\n{code}\n```", parse_mode='Markdown')
    else:
        bot.send_message(user_id, f"âŒ Error: {response.get('error')}")
    
    bot.send_message(user_id, "\n à¤”à¤°?", reply_markup=get_main_menu())

# ============ MEMORY HANDLERS ============
@bot.message_handler(func=lambda m: "My Memory" in m.text)
@error_handler
def handle_memory_menu(message):
    user_id = message.chat.id
    history = conversation_memory.get_history(user_id)
    
    info = f"""
ğŸ§  **MEMORY MANAGEMENT**

à¤†à¤ªà¤•à¥€ memory à¤®à¥‡à¤‚ {len(history)} messages à¤¹à¥ˆà¤‚à¥¤
"""
    
    bot.send_message(user_id, info, reply_markup=get_memory_menu(), parse_mode='Markdown')

@bot.message_handler(func=lambda m: "View History" in m.text)
@error_handler
def handle_view_history(message):
    user_id = message.chat.id
    history = conversation_memory.get_history(user_id, last_n=10)
    
    if not history:
        bot.send_message(user_id, "ğŸ§  à¤…à¤­à¥€ à¤•à¥‹à¤ˆ conversation à¤¯à¤¾à¤¦ à¤¨à¤¹à¥€à¤‚ à¤¹à¥ˆà¥¤")
        return
    
    history_text = "ğŸ“œ **Your Conversation History:**\n\n"
    for i, entry in enumerate(history, 1):
        emoji = "ğŸ‘¤" if entry["role"] == "user" else "ğŸ¤–"
        msg_preview = entry["message"][:60] + "..." if len(entry["message"]) > 60 else entry["message"]
        history_text += f"{i}. {emoji} {msg_preview}\n"
    
    bot.send_message(user_id, history_text, parse_mode='Markdown')
    bot.send_message(user_id, "\n à¤”à¤° à¤•à¥à¤¯à¤¾?", reply_markup=get_memory_menu())

@bot.message_handler(func=lambda m: "Memory Stats" in m.text)
@error_handler
def handle_memory_stats(message):
    stats = conversation_memory.get_stats()
    
    stats_text = f"""
ğŸ“Š **MEMORY STATISTICS**

ğŸ“ˆ Total Users: {stats['total_users']}
ğŸ“ Total Messages: {stats['total_messages']}
ğŸ’¾ Max/User: {stats['max_size']}

ğŸ” Your History: {len(conversation_memory.get_history(message.chat.id))} messages
"""
    
    bot.send_message(message.chat.id, stats_text, parse_mode='Markdown')

@bot.message_handler(func=lambda m: "Clear Memory" in m.text)
@error_handler
def handle_clear_memory(message):
    conversation_memory.clear_history(message.chat.id)
    bot.send_message(message.chat.id, "ğŸ—‘ï¸ Memory cleared!\n\nà¤¨à¤ˆ conversation à¤¶à¥à¤°à¥‚ à¤•à¤°à¥‹à¥¤", reply_markup=get_main_menu())

# ============ SMART CHAT HANDLER ============
@bot.message_handler(func=lambda m: "Smart Chat" in m.text)
@error_handler
def handle_smart_chat(message):
    if not rate_limiter.is_allowed(message.chat.id, 'standard'):
        bot.send_message(message.chat.id, "âš ï¸ Rate limit.")
        return
    
    msg = bot.send_message(
        message.chat.id,
        "ğŸ’¬ **SMART CHAT MODE**\n\nà¤…à¤ªà¤¨à¤¾ à¤¸à¤µà¤¾à¤² à¤¯à¤¾ à¤¬à¤¾à¤¤ à¤¬à¤¤à¤¾à¤“:",
        parse_mode='Markdown'
    )
    bot.register_next_step_handler(msg, process_smart_chat)

def process_smart_chat(message):
    user_id = message.chat.id
    
    if not rate_limiter.is_allowed(user_id, 'standard'):
        bot.send_message(user_id, "âš ï¸ Rate limit")
        return
    
    conversation_memory.add_message(user_id, "user", message.text)
    
    thinking = bot.send_message(user_id, "ğŸ’¬ à¤¸à¥‹à¤š à¤°à¤¹à¤¾ à¤¹à¥‚à¤...")
    context = conversation_memory.get_context_string(user_id, last_n=3)
    response = ai_client.standard_chat(message.text, context)
    
    if "error" not in response:
        ai_reply = response.get("response", "à¤•à¥‹à¤ˆ reply à¤¨à¤¹à¥€à¤‚")
        conversation_memory.add_message(user_id, "bot", ai_reply)
        
        if len(ai_reply) > 4096:
            for i in range(0, len(ai_reply), 4096):
                bot.send_message(user_id, ai_reply[i:i+4096])
            bot.delete_message(user_id, thinking.message_id)
        else:
            bot.edit_message_text(ai_reply, user_id, thinking.message_id)
    else:
        bot.edit_message_text(f"âŒ Error: {response['error']}", user_id, thinking.message_id)
    
    bot.send_message(user_id, "\n à¤”à¤°?", reply_markup=get_main_menu())

# ============ TRANSLATION HANDLER ============
@bot.message_handler(func=lambda m: "Translate" in m.text)
@error_handler
def handle_translate(message):
    if not rate_limiter.is_allowed(message.chat.id, 'standard'):
        bot.send_message(message.chat.id, "âš ï¸ Rate limit")
        return
    
    msg = bot.send_message(
        message.chat.id,
        "ğŸŒ **TRANSLATION MODE**\n\nà¤•à¥à¤¯à¤¾ translate à¤•à¤°à¤¨à¤¾ à¤¹à¥ˆ?",
        parse_mode='Markdown'
    )
    bot.register_next_step_handler(msg, process_translate)

def process_translate(message):
    user_id = message.chat.id
    
    conversation_memory.add_message(user_id, "user", f"Translate: {message.text}")
    
    bot.send_message(user_id, "ğŸŒ Translate à¤¹à¥‹ à¤°à¤¹à¤¾ à¤¹à¥ˆ...")
    response = ai_client.translate(message.text, "hindi")
    
    if "error" not in response:
        translation = response.get('translated_text', 'No translation')
        conversation_memory.add_message(user_id, "bot", translation)
        bot.send_message(user_id, f"âœ… **Translated:**\n\n{translation}")
    else:
        bot.send_message(user_id, f"âŒ Error: {response.get('error')}")
    
    bot.send_message(user_id, "\n à¤”à¤°?", reply_markup=get_main_menu())

# ============ DEFAULT HANDLER ============
@bot.message_handler(func=lambda m: True)
@error_handler
def handle_default(message):
    user_id = message.chat.id
    
    if not rate_limiter.is_allowed(user_id, 'standard'):
        bot.send_message(user_id, "âš ï¸ Rate limit")
        return
    
    intent = intent_recognizer.recognize_intent(message.text)
    
    if intent["type"] == "deep_thinking":
        handle_deep_thinking_mode(message)
    elif intent["type"] == "image":
        handle_image_mode(message)
    elif intent["type"] == "video":
        handle_video_mode(message)
    elif intent["type"] == "code":
        handle_code_mode(message)
    elif intent["type"] == "translate":
        handle_translate(message)
    else:
        handle_smart_chat(message)

# ============ FLASK SERVER ============
def run_flask():
    app.run(host='0.0.0.0', port=PORT, debug=False, use_reloader=False)

# ============ MAIN ============
if __name__ == "__main__":
    logger.info("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸš€ ULTIMATE ADVANCED TELEGRAM AI BOT v2.0 ğŸš€    â•‘
â•‘                                                   â•‘
â•‘  Features Enabled:                                â•‘
â•‘  âœ… Deep Thinking AI (Claude-Level)              â•‘
â•‘  âœ… Image Generation (6 Styles)                  â•‘
â•‘  âœ… Video Generation                             â•‘
â•‘  âœ… Advanced Code Generation                     â•‘
â•‘  âœ… Translation (50+ Languages)                  â•‘
â•‘  âœ… Smart Conversation Memory                    â•‘
â•‘  âœ… Advanced NLP Intent Recognition              â•‘
â•‘  âœ… Rate Limiting & Security                     â•‘
â•‘                                                   â•‘
â•‘  Starting up...                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    logger.info(f"ğŸ”— API URL: {AI_API_URL}")
    logger.info(f"ğŸ§  Deep Thinking Model: {DEEP_THINKING_MODEL}")
    logger.info(f"ğŸ’¬ Standard Model: {STANDARD_MODEL}")
    logger.info(f"ğŸŒ Flask Port: {PORT}")
    logger.info(f"ğŸ“Š API Health: {'âœ… HEALTHY' if ai_client.check_health() else 'âŒ OFFLINE'}")
    
    # Start Flask
    flask_thread = threading.Thread(target=run_flask, daemon=True)
    flask_thread.start()
    logger.info(f"âœ… Flask server started on port {PORT}")
    
    try:
        logger.info("ğŸš€ Bot polling started...")
        logger.info("\nâœ¨ Bot is LIVE! Ready to serve!\n")
        bot.infinity_polling()
    except Exception as e:
        logger.error(f"âŒ Bot error: {e}")
        raise
